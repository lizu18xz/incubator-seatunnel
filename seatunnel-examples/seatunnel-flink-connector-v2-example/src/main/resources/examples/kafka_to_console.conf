#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
######
###### This config file is a demonstration of streaming processing in seatunnel config
######

env {
  # You can set flink configuration here
  execution.parallelism = 2
  job.mode = "STREAMING"
  execution.checkpoint.interval = 30000
  #execution.checkpoint.data-uri = "hdfs://localhost:9000/checkpoint"
}

source {
  # This is a example source plugin **only for test and demonstrate the feature source plugin**
   Kafka {
      bootstrap.servers = "addon-kafka-i1.default.svc.cluster.local:9092"
      topic = "dstest01"
      result_table_name = "kafka_table"
      # The default format is json, which is optional
      format = json
      start_mode = latest
      format_error_handle_way = skip
      result_table_name="t1"
      json_field = {
        content = "$.content"
        time = "$.time"
        stream = "$.stream"
        id = "$.id"
        source = "$.source"
        level = "$.tags.level"
        application_id = "$.tags.application_id"
        dice_application_id = "$.tags.dice_application_id"
        application_name = "$.tags.application_name"
      }
      schema = {
        fields {
          content = string
          time = string
          stream = string
          id = string
          source = string
          level = string
          application_id = string
          dice_application_id = string
          application_name = string
      }
    }

    }

  # If you would like to get more information about how to configure seatunnel and see full list of source plugins,
  # please go to https://seatunnel.apache.org/docs/category/source-v2
}

transform {

}

sink {

  Console {
    parallelism = 1
  }

  Doris {
    fenodes = "10.167.0.54:8030"
    username = root
    password = "Hello123"
    table.identifier = "cdp.kafka_table_sink"
    sink.label-prefix = "test-doris-02"
    sink.enable-2pc = "true"
    sink.enable-delete = "false"
    doris.config {
       format="json"
       read_json_by_line="true"
    }
  }

  # If you would like to get more information about how to configure seatunnel and see full list of sink plugins,
  # please go to https://seatunnel.apache.org/docs/category/sink-v2
}